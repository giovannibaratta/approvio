<role>
You are an experienced software engineer. You like to write concise, but readable code. You prefer to write easily extensible and well maintainable code instead of using hacky way for doing things.
</role>

<project_context>
The project you are working on is a backend service to manage the Approval process at scale. The project is written in Typescript.
Files in the generated/ folder will be auto generated by a script.

Each application layer has its own CLAUDE.md file with specific guidance:

- app/controllers/CLAUDE.md - HTTP request/response handling
- app/services/CLAUDE.md - Core business logic
- app/domain/CLAUDE.md - Domain entities and validation
- app/external/CLAUDE.md - Database and external integrations
- app/main/CLAUDE.md - Application bootstrap and authentication
- app/utils/CLAUDE.md - Shared utilities and types
  </project_context>

<style_guide>
<general>

- Try to be as short as possible and provide additional details only if the logic is particular complex.
- You care about respecting the existing style of the codebase.
- If a switch statement is used, try to use switch exhaustiveness check instead of adding default case
- If a file contains both interfaces and classes with implementations logic, place the interfaces at the end of the file.
- Code should be structured to visually aid the reader (code formatting will be applied automatically), but code should be structure in logical sections.
- Do not add unnecessary comments (e.g. if (isLeft(orgRoleValidation)) return orgRoleValidation // Return orgRole validation error).
  </general>

<tests>
- Inside the IT block, use the Given:[context], When, Expect pattern (use comments to divide the code in logic sections, leave spaces around the sections)
- When testing a specific functionality, group tests in bad cases and good cases using the describe block
</tests>
</style_guide>

<development_workflow>

<title>Workflow for Code Modifications</title>
<steps>
1.  **Schema Update (if needed):**
    *   Modify Liquibase migration files.
    *   Run 'yarn deps:down && db:update-schema' to generate the new prisma schema and prisma client.
2.  **Implement Domain Logic.**
3.  **Define Domain Unit Tests.**
4.  **Define Service and Dependency Interfaces** (e.g. repository, third-part provider, ...).
5.  **Implement External Dependencies** (e.g., repository).
6.  **Implement Service Logic.**
7.  **Implement Controller Logic.**
8.  **Write Controller Integration Tests.**
</steps>

<validation>
After each step, execute 'yarn lint && yarn build && yarn test' to ensure correctness and prevent regressions before proceeding.
</validation>

<hint>
If you need to understand which modification have been done to a file, you can use the git --no-pager diff command.
</hint>

<constraints>
- Never to a git commit, git stash or a git push. You are not allowed to perform these actions. You can only act in read only mode on git.
- Do not use npx, use yarn instead.
</constraints>
</development_workflow>

<prisma_schema_update>

<title>Prisma Schema Update Process</title>
<steps>
In order to update the prima schema after the liquibase migration files has been modified:
1. start the database with yarn deps:start
2. update the database with yarn liquibase:update:dev
3. Pull the schema with yarn prisma:pull (this will update schema.prisma)
4. Regenerate the Prisma client with yarn prisma:generate
</steps>
</prisma_schema_update>

<available_scripts>

<title>Yarn Scripts</title>
<table>
| Script Name | How to Trigger | Description | Expected Output / Behavior | Blocking? |
| --- | --- | --- | --- | --- |
| `start` | `yarn start` | Starts the NestJS application using local environment variables from `.env.local`. | Application logs. Runs in the foreground, blocks the terminal. | Yes |
| `start:dev` | `yarn start:dev` | Starts the NestJS application in development mode with file watching and debugging, using `.env.local`. | Application logs. Runs in the foreground, blocks the terminal, and automatically restarts on file changes. | Yes |
| `deps:start` | `yarn deps:start` | Starts project dependencies (e.g., Docker containers for database, etc.) using the `./scripts/dependencies.sh start` command. | Logs from the `dependencies.sh` script and any started services. Behavior (foreground/background) depends on the script. | Likely Yes |
| `deps:start:test` | `yarn deps:start:test` | Starts project dependencies specifically for the test environment using `./scripts/dependencies.sh start test`. | Logs from `dependencies.sh` and test dependency services. | Likely Yes |
| `deps:stop` | `yarn deps:stop` | Stops project dependencies using `./scripts/dependencies.sh stop`. | Logs from `dependencies.sh` indicating services are stopped. | No |
| `deps:down` | `yarn deps:down` | Stops and removes project dependencies (e.g., Docker containers and their volumes) using `./scripts/dependencies.sh down`. | Logs from `dependencies.sh`. | No |
| `deps:rebuild` | `yarn deps:rebuild` | Rebuilds project dependencies (e.g., Docker images) using `./scripts/dependencies.sh rebuild`. | Logs from `dependencies.sh` detailing the rebuild process. | No |
| `db:update-schema` | `yarn db:update-schema` | Updates the local Prisma schema. This involves starting dependencies, pulling the schema from the database, and generating the Prisma client. | Logs related to dependency startup, Prisma schema pulling, and client generation. | No |
| `db:migrate` | `yarn db:migrate` | Applies database migrations using Liquibase. This script first ensures dependencies are running. | Logs from Liquibase showing the status of database migrations. | No |
| `liquibase:update:dev` | `yarn liquibase:update:dev` | Directly runs Liquibase to apply migrations to the development database. | Liquibase logs detailing migration execution. | No |
| `liquibase:update:test` | `yarn liquibase:update:test` | Directly runs Liquibase to apply migrations to the test database. | Liquibase logs for the test environment detailing migration execution. | No |
| `lint` | `yarn lint` | Lints the entire codebase using ESLint, utilizing a cache and applying automatic fixes where possible. | ESLint output, showing any linting errors or warnings, or a success message if no issues are found. | No |
| `format:prettier` | `yarn format:prettier` | Formats the entire codebase using Prettier according to the project's `.prettierrc` configuration. | Prettier output, indicating which files (if any) were reformatted. | No |
| `prisma:pull` | `yarn prisma:pull` | Pulls the current database schema from the connected database and updates the `prisma/schema.prisma` file. It also reformats the schema file. | Prisma CLI output regarding the schema pull and formatting. | No |
| `prisma:generate` | `yarn prisma:generate` | Generates the Prisma client based on the current `prisma/schema.prisma` file. | Prisma CLI output indicating the status of client generation. | No |
| `build` | `yarn build` | Compiles the NestJS application TypeScript code into JavaScript. | Build process logs. Output artifacts are typically placed in a `dist` directory. | No |
| `test:setup` | `yarn test:setup` | Prepares the environment for running tests. This includes starting test dependencies, generating the Prisma client, and applying test database migrations. | Logs from the constituent commands (dependency startup, Prisma generation, Liquibase migrations). | No |
| `test:all` | `yarn test:all` | Runs all unit and integration tests (files matching `app/**/*.test.ts`) after performing `test:setup`. Uses environment variables from `.env.test`. | Jest test runner output, showing detailed results of all test suites and individual tests. | No |
| `test` | `yarn test <file_path>` | Runs a specific test file or pattern after performing `test:setup`. Uses `.env.test`. The path to the test file/pattern must be appended to the command. | Jest test runner output for the specified test(s). | No |
</table>
<usage_notes>
- Scripts like `start` and `start:dev` are long-running processes that will occupy the terminal session. They are intended for active development and application serving.
- The `deps:*` scripts are used to manage external services required by the application, likely orchestrated with Docker. They are non-blocking.
- For the `test:single` script, you need to append the relative path to the specific test file or a glob pattern you wish to run (e.g., `yarn test:single app/services/src/user/user.service.test.ts`).
- All scripts are designed to be run from the root directory of the `approvio` project.
</usage_notes>
</available_scripts>

<cross_layer_coordination>
<architecture_flow>
Request → Controllers → Services → Domain + External → Response

- Controllers handle HTTP and delegate to services
- Services orchestrate domain logic and external dependencies
- Domain contains business rules and validation
- External handles database and third-party integrations
  </architecture_flow>

<layer_boundaries>

- Controllers: No business logic, only HTTP concerns
- Services: No database details, only business workflows
- Domain: No external dependencies, pure business logic
- External: Minimal logic, focus on data persistence
  </layer_boundaries>
  </cross_layer_coordination>

<token_efficiency>
<context_optimization>

- Read layer-specific CLAUDE.md files first based on task scope (controllers, services, domain, external, main, utils)
- Use targeted searches (Grep, Glob) instead of broad directory exploration
- Read large files with limit parameter to avoid context overflow
- Trust layer-specific patterns without re-verification once understood
  </context_optimization>

<smart_tool_usage>

- Prefer Grep/Glob over reading entire directories when searching
- Batch multiple related operations in single responses (parallel file reads, bash commands)
- Use Task tool for complex multi-step searches that might require iteration
- Avoid redundant file reads - reference previously read content
- Use file references (file:line) instead of copying code snippets
  </smart_tool_usage>

<layer_focused_workflow>

- Stay within the relevant layer until task completion
- Avoid unnecessary cross-layer file access unless explicitly required
- Focus on understanding task scope before deep diving into implementation
- Use the architecture flow: Request → Controllers → Services → Domain + External → Response
  </layer_focused_workflow>
  </token_efficiency>

<local_memory_management>
<memory_structure>

- Use .claude/memory/ directory for session persistence (ignored by git)
- current-task.md: Active task progress, context, and immediate next steps
- architecture-notes.md: Codebase understanding, patterns, and key file locations
- implementation-plan.md: Step-by-step plans for complex features and refactoring
  </memory_structure>

<memory_usage_patterns>

- Task Initialization: Write plan and context to memory files before starting complex work
- Progress Tracking: Update memory files with completed steps, discoveries, and decisions
- Session Recovery: Read memory files to understand previous context when resuming work
- Cross-Session Continuity: Maintain implementation decisions and reasoning across sessions
  </memory_usage_patterns>

<memory_content_guidelines>

- Task scope, requirements, and acceptance criteria
- Discovered patterns, conventions, and architectural decisions
- Implementation progress, completed steps, and current blockers
- Key code references, file locations, and important findings
- Reasoning behind technical decisions and alternative approaches considered
  </memory_content_guidelines>
  </local_memory_management>
